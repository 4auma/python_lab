# normilaze
def normalize(text: str, *, casefold: bool = True, yo2e: bool = True) -> str:
    for i in '\n\t\r':
        text = text.replace(i," ")
    if yo2e==True:
        text = text.replace("Ñ‘","Ðµ").replace("Ð","Ð•")
    if casefold:
        text = text.casefold()
    while "  " in text:
        text = text.replace("  ", " ")
    return text.strip()
# Ð’Ñ‹Ð²Ð¾Ð´:
assert normalize("ÐŸÑ€Ð˜Ð²Ð•Ñ‚\nÐœÐ˜Ñ€\t") == "Ð¿Ñ€Ð¸Ð²ÐµÑ‚ Ð¼Ð¸Ñ€"
assert normalize("Ñ‘Ð¶Ð¸Ðº, ÐÐ»ÐºÐ°") == "ÐµÐ¶Ð¸Ðº, ÐµÐ»ÐºÐ°"

# tokenize 
def tokenize(text: str) -> list[str]:
    for i in ",!:ðŸ˜€":
        text=text.replace(i,"")
    text=text.strip()
    text=text.split()
    return text
# Ð’Ñ‹Ð²Ð¾Ð´:
assert tokenize("Ð¿Ñ€Ð¸Ð²ÐµÑ‚, Ð¼Ð¸Ñ€!") == ["Ð¿Ñ€Ð¸Ð²ÐµÑ‚", "Ð¼Ð¸Ñ€"]
assert tokenize("Ð¿Ð¾-Ð½Ð°ÑÑ‚Ð¾ÑÑ‰ÐµÐ¼Ñƒ ÐºÑ€ÑƒÑ‚Ð¾") == ["Ð¿Ð¾-Ð½Ð°ÑÑ‚Ð¾ÑÑ‰ÐµÐ¼Ñƒ", "ÐºÑ€ÑƒÑ‚Ð¾"]
assert tokenize("2025 Ð³Ð¾Ð´") == ["2025", "Ð³Ð¾Ð´"]
assert tokenize("emoji ðŸ˜€ Ð½Ðµ ÑÐ»Ð¾Ð²Ð¾") == ["emoji", "Ð½Ðµ", "ÑÐ»Ð¾Ð²Ð¾"]

# count_freq.py
def count_freq(tokens: list[str]) -> dict[str, int]:
    f=[]
    d=[]
    g=[]
    k=set(tokens)
    for i in k:
       m=tokens.count(i)
       g.append(f"{i}:{m}")
       k=g[:2]
    return f" Ð§Ð°ÑÑ‚Ð¾Ñ‚Ð° {sorted(g)}",f" Ð¢Ð¾Ð¿ - 2 ÑÐ»Ð¾Ð² {sorted(k)}"
# Ð’Ñ‹Ð²Ð¾Ð´:
assert count_freq(["a","b","a","c","b","a"]) == (" Ð§Ð°ÑÑ‚Ð¾Ñ‚Ð° ['a:3', 'b:2', 'c:1']", " Ð¢Ð¾Ð¿ - 2 ÑÐ»Ð¾Ð² ['a:3', 'b:2']")

# top_n+count_freq.py
def count_freq(tokens: list[str]) -> dict[str, int]:
    # Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÑŽ ÑÐ»Ð¾Ð²Ð°Ñ€ÑŒ Ð´Ð»Ñ Ð¿Ð¾Ð´ÑÑ‡ÐµÑ‚Ð° ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð° Ð¾Ð´Ð¸Ð½Ð°ÐºÐ¾Ð²Ñ‹Ñ… ÑÐ»Ð¾Ð²
    freq_dict={}
    
    for token in tokens:
        if token in freq_dict:
            freq_dict[token] += 1
        else:
            freq_dict[token] = 1

def top_n(freq: dict[str, int], n: int = 5) -> list[tuple[str, int]]:
    sorted_items = sorted(freq.items(), key=lambda x: (-x[1], x[0]))
    return sorted_items[:n]
# Ð’Ñ‹Ð²Ð¾Ð´:
freq2 = count_freq(["bb","aa","bb","aa","cc"])
assert top_n(freq2, 2) == [("aa",2), ("bb",2)]